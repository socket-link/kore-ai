package link.socket.kore.model.capability

import kotlinx.coroutines.CoroutineScope
import kotlinx.serialization.json.*
import link.socket.kore.data.ConversationRepository
import link.socket.kore.model.agent.KoreAgent
import link.socket.kore.model.agent.bundled.agentArgsList
import link.socket.kore.model.agent.bundled.agentNameList
import link.socket.kore.model.agent.bundled.getAgentDefinition
import link.socket.kore.model.tool.FunctionProvider
import link.socket.kore.model.tool.ParameterDefinition

/**
 * Represents a capability that an agent can possess.
 */
sealed interface AgentCapability : Capability {

    /**
     * Capability to get a list of available LLM agents.
     */
    data object GetAgents : AgentCapability {

        override val impl: Pair<String, FunctionProvider> =
            FunctionProvider.provide(
                name = "getAgents",
                description = "Returns a list of available LLM Agents.",
                function = GetAgents::getAgents,
            )

        /**
         * Returns a comma-separated list of agent names.
         */
        private fun getAgents(): String = agentNameList.joinToString(", ")
    }

    /**
     * Capability to get a list of available LLM agents along with their respective arguments.
     */
    data object GetAgentArgs : AgentCapability {

        override val impl: Pair<String, FunctionProvider> =
            FunctionProvider.provide(
                name = "getAgentArgs",
                description = "Returns a list of available LLM Agents, along with their respective arguments.",
                function = GetAgentArgs::getAgentArgs,
            )

        /**
         * Returns a newline-separated list of agent arguments.
         */
        private fun getAgentArgs(): String = agentArgsList.joinToString("\n\n")
    }

    /**
     * Capability to prompt another agent for completion based on given inputs.
     *
     * @property conversationRepository Repository to manage conversation data.
     * @property scope Coroutine scope for managing asynchronous operations.
     */
    data class PromptAgent(
        val conversationRepository: ConversationRepository,
        val scope: CoroutineScope,
    ) : AgentCapability {

        override val impl: Pair<String, FunctionProvider> =
            FunctionProvider.provideSuspend(
                name = "promptAgent",
                description = """
                    Requests a completion from another Agent with the given prompt and an example user's response to the LLM's initial Chat.
                    Returns the Chat completion generated by the sub-Agent.
                    You must provide either an Agent name or a prompt, but **never** both.
                """.trimIndent(),
                function = { args: JsonObject ->
                    val agent = args.getOrElse("agent") {
                        JsonPrimitive("")
                    }.jsonPrimitive.content
                    val prompt = args.getOrElse("prompt") {
                        JsonPrimitive("")
                    }.jsonPrimitive.content
                    val initialUserChat = args.getOrElse("initialUserChat") {
                        JsonPrimitive("")
                    }.jsonPrimitive.content

                    promptAgent(scope, agent, prompt, initialUserChat)
                },
                parameterList = listOf(
                    ParameterDefinition(
                        name = "agent",
                        isRequired = false,
                        definition = buildJsonObject {
                            put("type", "string")
                            put("description", "The name of the LLM Agent that should be completing the prompt. *Cannot* be used if prompt is being sent.")
                        }
                    ),
                    ParameterDefinition(
                        name = "prompt",
                        isRequired = false,
                        definition = buildJsonObject {
                            put("type", "string")
                            put("description", "The system instructions to use in case an Agent is not specified. *Cannot* be used if an agent is being sent.")
                        }
                    ),
                    ParameterDefinition(
                        name = "initialUserChat",
                        isRequired = false,
                        definition = buildJsonObject {
                            put("type", "string")
                            put(
                                "description",
                                """
                                    Send an initial User Chat message to the Agent, which will be submitted to 
                                    the Agent after the Agent's first response is generated.
                                    
                                    This property should be used when you know what question you want to ask the Agent
                                    and you don't want to wait for the Agent's initial response to ask the question.
                                """.trimIndent()
                            )
                        }
                    )
                )
            )

        /**
         * Requests a completion from another Agent.
         *
         * @param scope Coroutine scope for managing asynchronous operations.
         * @param agentName Optional name of the LLM Agent.
         * @param prompt The system instructions to use.
         * @param initialUserPrompt Optional to send an initial User Chat message to the Agent.
         * @return The Chat completion generated by the sub-Agent.
         */
        private suspend fun promptAgent(
            scope: CoroutineScope,
            agentName: String?,
            prompt: String?,
            initialUserPrompt: String?,
        ): String {
            val agent = KoreAgent(
                scope,
                agentName.getAgentDefinition(prompt),
                conversationRepository,
            )

            val conversationId = conversationRepository.createConversation(agent, null)

            if (initialUserPrompt != null) {
                // Option to get the _second_ LLM response, after a User provides their initial reply to the _first_ LLM response
                conversationRepository.runConversation(conversationId)
                conversationRepository.addUserChat(
                    conversationId = conversationId,
                    input = initialUserPrompt,
                )
            }

            conversationRepository.runConversation(conversationId)

            return conversationRepository
                .getValue(conversationId)
                ?.conversationHistory
                ?.getChats()
                ?.lastOrNull()
                ?.chatMessage
                ?.content ?: ""
        }
    }
}
